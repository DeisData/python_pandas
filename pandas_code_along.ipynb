{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "injured-intranet",
   "metadata": {},
   "source": [
    "# Python Pandas\n",
    "\n",
    "One of the best options for working with tabular data in Python is to use the \n",
    "**Python Data Analysis Library (Pandas)**. \n",
    "The Pandas library provides data structures, produces high quality plots with matplotlib and integrates nicely with other libraries that use NumPy (which is another Python library) arrays.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library as a alias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure figures appear inline in Ipython Notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-bench",
   "metadata": {},
   "source": [
    "### Read in data comma separated value file into data frame \n",
    "<img src=\"images/import.png\" alt=\"import data\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that pd.read_csv is used because we imported pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-extraction",
   "metadata": {},
   "source": [
    "### What is our data?\n",
    "<img src=\"images/metadata.png\" alt=\"data description\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-corner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "prostate-advice",
   "metadata": {},
   "source": [
    "## Useful Ways to View DataFrame objects in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-trailer",
   "metadata": {},
   "source": [
    "Summarize and access the data stored in DataFrames using attributes and methods provided by the DataFrame object.\n",
    "\n",
    "**Attributes** are accessed using the DataFrame object name followed by the attribute name `df_object.attribute`\n",
    "\n",
    "Examples of attributes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape (dimensions) of array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-gathering",
   "metadata": {},
   "source": [
    "**Methods** are called using the syntax `df_object.method()` \n",
    "\n",
    "Examples of methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the start of the data:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-poverty",
   "metadata": {},
   "source": [
    "## Quick Statistics in a Pandas DataFrame\n",
    "\n",
    "Let’s get a list of all the species. \n",
    "The `pd.unique` function tells us all of the unique values in the species_id column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique list of species\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-claim",
   "metadata": {},
   "source": [
    "### Groups in Pandas\n",
    "\n",
    "We often want to calculate summary statistics grouped by subsets or attributes within fields of our data. For example, we might want to calculate the average weight of all individuals per site.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can calculate basic statistics for all records in a single column:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or all numeric data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-fitting",
   "metadata": {},
   "source": [
    "But if we want to summarize by one or more variables, for example sex, we can use Pandas `.groupby` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-answer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by sex\n",
    "\n",
    "\n",
    "# Summary statistics for all numeric columns by sex\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-ceiling",
   "metadata": {},
   "source": [
    "### Creating Summary Counts in Pandas\n",
    "\n",
    "Let’s next count the number of samples for each species. \n",
    "Use `groupby` combined with a `count()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of samples by species\n",
    "\n",
    "#print(species_counts)\n",
    "\n",
    "# Create a quick bar chart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-colorado",
   "metadata": {},
   "source": [
    "### How do I create a new column from existing columns?  \n",
    "If we wanted to, we could perform math on an entire column (or columns) of our data and add it to the dataframe.\n",
    "\n",
    "<img src=\"images/newcol.png\" alt=\"new column\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of basic math normalizing weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-stand",
   "metadata": {},
   "source": [
    "To create a new column, use the `[]` brackets with the new column name at the left side of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(surveys_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-guarantee",
   "metadata": {},
   "source": [
    "# Indexing, Slicing and Subsetting DataFrames in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-flour",
   "metadata": {},
   "source": [
    "Selecting data using Labels (Column Headings)\n",
    "We use square brackets `[]` to select a subset of a Python object. \n",
    "\n",
    "<img src=\"images/subset.png\" alt=\"subsetting\" width=\"500\"/>\n",
    "\n",
    "For example, we can select all data from a column named `species_id` from the `surveys_df` DataFrame by name. \n",
    "There are two ways to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: select a 'subset' of the data using the column name\n",
    "\n",
    "\n",
    "# Method 2: use the column name as an 'attribute'; gives the same output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-cooperative",
   "metadata": {},
   "source": [
    "We can also create a new object that contains only the data within the species_id column as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an object, surveys_species, that only contains the `species_id` column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the species and plot columns from the DataFrame\n",
    "\n",
    "# What happens when you flip the order?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-threshold",
   "metadata": {},
   "source": [
    "### Extracting Range based Subsets: Slicing\n",
    "Slicing using the `[]` operator selects a set of rows and/or columns from a DataFrame. \n",
    "To slice out a set of rows, you use the following syntax: `data[start:stop]`. \n",
    "\n",
    "When slicing in pandas the start bound is included in the output. The stop bound is one step BEYOND the row you want to select. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows 0, 1, 2 (row 3 is not selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first 5 rows (rows 0, 1, 2, 3, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the last element in the list\n",
    "# (the slice starts at the last element, and ends at the end of the list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-browser",
   "metadata": {},
   "source": [
    "### Slicing Subsets of Rows and Columns in Python\n",
    "\n",
    "We can select specific ranges of our data in both the row and column directions using either label or integer-based indexing.\n",
    "\n",
    "- loc is primarily label based indexing. Integers may be used but they are interpreted as a label.\n",
    "- iloc is primarily integer based indexing\n",
    "\n",
    "To select a subset of rows and columns from our DataFrame, we can use the iloc method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc[row slicing, column slicing]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-acting",
   "metadata": {},
   "source": [
    "Let’s explore some other ways to index and select subsets of data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all columns for rows of index values 0 and 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does this do?\n",
    "surveys_df.loc[0, ['species_id', 'plot_id', 'weight']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens when you type the code below?\n",
    "#surveys_df.loc[[0, 10, 35549], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-potential",
   "metadata": {},
   "source": [
    "### Subsetting Data using Criteria\n",
    "We can use the syntax below when querying data by criteria from a DataFrame. \n",
    "\n",
    "- Equals: `==`\n",
    "- Not equals: `!=`\n",
    "- Greater than, less than: `>` or `<`\n",
    "- Greater than or equal to `>=`\n",
    "- Less than or equal to `<=`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all rows that have a year value of 2002\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can define sets of criteria too:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-virgin",
   "metadata": {},
   "source": [
    "## Export a dataframe to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-grade",
   "metadata": {},
   "source": [
    "Next, let’s drop all the rows that contain missing values using `dropna`. \n",
    "By default, dropna removes rows that contain missing data for even just one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_na = surveys_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-cancer",
   "metadata": {},
   "source": [
    "We can now use the to_csv command to export a DataFrame in CSV format. \n",
    "Note that the code below will by default save the data into the current working directory. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DataFrame to CSV\n",
    "df_na.to_csv('surveys_complete.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-logistics",
   "metadata": {},
   "source": [
    "# Combining DataFrames with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-mistake",
   "metadata": {},
   "source": [
    "In many research situations, the data that we want to use come in multiple files. We often need to combine these files into a single DataFrame to analyze the data. The pandas package provides various methods for combining DataFrames including `merge` and `concat`.\n",
    "\n",
    "Load the species and surveys files into pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-northern",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-smoke",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-video",
   "metadata": {},
   "source": [
    "### Concatenating DataFrames\n",
    "Use the `concat` function in pandas to append either columns or rows from one DataFrame to another. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in first 10 lines of surveys table\n",
    "survey_sub = \n",
    "\n",
    "# Grab the last 10 rows\n",
    "survey_sub_last10 = \n",
    "\n",
    "# Reset the index values to the second dataframe appends properly\n",
    "\n",
    "     # drop=True option avoids adding new index column with old index values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-origin",
   "metadata": {},
   "source": [
    "When we concatenate DataFrames, we need to specify the axis. \n",
    "\n",
    "- axis=0 tells pandas to stack the second DataFrame UNDER the first one. It will automatically detect whether the column names are the same and will stack accordingly. \n",
    "- axis=1 will stack the columns in the second DataFrame to the RIGHT of the first DataFrame. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the DataFrames on top of each other\n",
    "vertical_stack = \n",
    "#print(vertical_stack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the DataFrames side by side\n",
    "horizontal_stack = \n",
    "#print(horizontal_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-breeding",
   "metadata": {},
   "source": [
    "## Joining Two DataFrames\n",
    "Combine or **join** DataFrames using columns in each dataset that contain common values. \n",
    "\n",
    "The columns containing the common values are called **join key(s)**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Identifying join keys\n",
    "# To identify appropriate join keys we first need to know \n",
    "# which field(s) are shared between the files (DataFrames). \n",
    "\n",
    "print(species_df.columns)\n",
    "\n",
    "print(surveys_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-preliminary",
   "metadata": {},
   "source": [
    "Join key is the column containing the two-letter species identifier, which is called `species_id.`\n",
    "\n",
    "There are different types of joins, so we need to decide which type of join makes sense for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-scanning",
   "metadata": {},
   "source": [
    "### Inner Join (default)\n",
    "\n",
    "The pandas function for performing joins is called `merge` and an Inner join is the default option:\n",
    "\n",
    "<img src=\"images/innerjoin.png\" alt=\"Inner Join\" width=\"250\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-plate",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_inner = \n",
    "\n",
    "# In this case `species_id` is the only column name in  both dataframes, so if we skipped `left_on`\n",
    "# And `right_on` arguments we would still get the same result\n",
    "\n",
    "# What's the size of the output data?\n",
    "print(merged_inner.shape)\n",
    "merged_inner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-greenhouse",
   "metadata": {},
   "source": [
    "The result `merged_inner` DataFrame contains all of the columns from `surveys_df` (record id, month, day, etc.) as well as all the columns from `species_df` (species_id, genus, species, and taxa)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-namibia",
   "metadata": {},
   "source": [
    "### Left joins\n",
    "What if we want to add information from `species_df` to `surveys_df` without losing any of the information from `surveys_df`? In this case, we use a different type of join called a **left join**.\n",
    "\n",
    "<img src=\"images/leftjoin.png\" alt=\"Left Join\" width=\"250\"/>\n",
    "\n",
    "A left join is performed in pandas by calling the same `merge` function used for inner join, but using the `how='left'` argument:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_left = \n",
    "merged_left"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-county",
   "metadata": {},
   "source": [
    "### References and Image Sources\n",
    "This lesson is based on the [Data Carpentry curriculum \"Data Analysis and Visualization in Python for Ecologists\"](\"https://datacarpentry.org/python-ecology-lesson/\") and the [Pandas Getting Started introductory tutorials](\"https://pandas.pydata.org/docs/getting_started/intro_tutorials/\").\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
